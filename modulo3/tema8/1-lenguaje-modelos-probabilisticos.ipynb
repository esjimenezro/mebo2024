{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lenguaje de los modelos probabilísticos\n",
    "\n",
    "![BLR](https://upload.wikimedia.org/wikipedia/commons/e/ed/Bayes_icon.svg)\n",
    "\n",
    "Hasta ahora hemos visto modelos de regresión lineal, usando inferencia exacta para la estimación de la distribución posterior de los parámetros, bajo un caso particular (suponiendo la varianza de la dispersión conocida). Si quisiéramos asumir previas distintas a la normal para los parámetros, incluyendo una previa para el parámetro de varianza, entonces la inferencia exacta de la distribución posterior se vuelve prácticamente imposible.\n",
    "\n",
    "En este tema, estudiamos el uso de muestreo de la distribución posterior usando técnicas Montecarlo, dándonos la libertad de elegir la previa que mejor represente nuestro conocimiento de la situación.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Adoptar un lenguaje estándar para definir modelos probabilísticos.\n",
    "> - Revisitar el modelo Gaussiano.\n",
    "\n",
    "> **Referencias:**\n",
    "> \n",
    "> - Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd edition) - Richard McElreath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Un lenguaje para escribir modelos probabilísticos.\n",
    "\n",
    "Lo primero, es aprender el lenguaje con el que se describen comúnmente los modelos probabilísticos. Este tipo de descripciones son bastante estándar en casi todos los artículos académicos y libros en general, tanto en modelamiento Bayesiano y no Bayesiano, por lo que entender este lenguaje nos será de mucha utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A alto nivel, la receta es la siguiente:\n",
    "\n",
    "1. Compilamos el conjunto de variables con el que vamos a trabajar. Algunas de estas variables son observables (las llamamos **datos**). Otras, no son observables, como tasas, medias, varianzas, entre otros... (las llamamos **parámetros**).\n",
    "2. Definimos cada variable en términos de otras, o bien en términos de una distribución de probabilidad.\n",
    "3. La combinación de las variables y sus distribuciones de probabilidad definen un **modelo generativo**, el cual puede usarse para simular observaciones hipotéticas o analizar observaciones reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta receta aplica en cada campo, desde ingeniería, hasta antropología. Normalmente, las dificultades radican en el área de estudio: ¿Cuáles variables son importantes y cómo las conectamos?\n",
    "\n",
    "Una vez se tenga esto claro, escribir el modelo es más o menos simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.** Consideremos, nuevamente, el caso de una moneda que tiramos $N$ veces. Queremos razonar acerca de las veces que la moneda cayó cara. \n",
    "\n",
    "Llamemos a la variable aleatoria del número de veces que la moneda cae cara $C$. Entonces:\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{array}{lcl}\n",
    "C & \\sim & \\text{Binomial}(N, p) \\\\\n",
    "p & \\sim & \\text{Uniform}(0, 1)\n",
    "\\end{array}\n",
    "\\end{align}\n",
    "\n",
    "En este ejemplo, $p$ es la probabilidad de que la moneda caiga cara en un solo tiro.\n",
    "\n",
    "La anterior descripción del modelo puede leerse como:\n",
    "> La cantidad de veces que la moneda cae cara $C$, distribuye binomial con tamaño de muestra $N$ y probabilidad $p$. La previa para $p$ se supone uniforme entre cero y uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al escribir el modelo de esta forma, involucramos todas las suposiciones. Por ejemplo, en la distribución binomial sabemos que cada tiro es independiente de otros, de forma que estamos modelando los datos como muestras iid.\n",
    "\n",
    "Una de las ventajas que comenzaremos a ver de ahora en adelante, es que en este **lenguaje probabilístico** nos distanciamos de las engorrosas formas matemáticas de las funciones de densidad, lo cual no significa que no las debamos tener presentes. Sin embargo, si es útil tener un lenguaje en el que resumamos todo el comportamiento, sin tener que estar escribiendo *tantas matemáticas*.\n",
    "\n",
    "En un modelo como el de arriba, la primera línea define la función de verosimilitud usada en el teorema de Bayes, mientras que las demás definen las previas.\n",
    "\n",
    "En el ejemplo, ambas relaciones son **estocásticas**, lo cual es indicado por el símbolo $\\sim$. Una relación estocástica es simplemente una relación de un parámetro a una distribución. Luego escribiremos modelos con relaciones **deterministas** dentro de ellos. Vamos a denotar relaciones deterministass por el símbolo $=$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelo Gaussiano de la altura.\n",
    "\n",
    "Ya que conocemos las bases de la escritura de modelos probabilísticos, construyamos un modelo nosotros mismos.\n",
    "\n",
    "Primero, modelaremos una variable como una distribución Gaussiana, la cual sabemos que tiene dos parámetros, la media $\\mu$ y la varianza $\\sigma^2$.\n",
    "\n",
    "La actualización Bayesiana, nos permitirá considerar cada combinación posible de $\\mu$ y $\\sigma$, y las ponderará de acuerdo a su plausibilidad de acuerdo a los datos, dando lugar a la distribución posterior de $\\mu$ y $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos que modelaremos corresponden a un censo parcial de la población [!Kung San en el área Dobe (sur de África)](https://laulima.hawaii.edu/access/content/user/millerg/ANTH_200/A200Unit1/DobeKung.html). Los !Kung San son la población nómada más famosa del siglo 20, y la más estudiada también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer datos (separados por ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método describe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que hay mucha variabilidad en los datos correspondientes a la altura. En parte, esto viene dado porque hay información de personas de todas las edades. Por ahora, nos concentraremos en la población adulta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer datos de adultos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método describe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar nuestro modelo, queremos modelar la altura de cada individuo como una distribución normal con media $\\mu$, y desviación estándar $\\sigma$:\n",
    "\n",
    "$$\n",
    "h_i \\sim \\text{Normal}(\\mu, \\sigma).\n",
    "$$\n",
    "\n",
    "> Ya no lo escribimos pero la suposición de iid va implícita en esta proposición.\n",
    "\n",
    "Como antes, esta definición define la función de verosimilitud. Para completar los ingredientes en la regla de Bayes, necesitamos la previa para nuestros parámetros $\\mu$ y $\\sigma$, $P(\\mu, \\sigma)$. Comúnmente, las previas se especifican de manera independiente para cada parámetro, lo que implica la suposición de $P(\\mu, \\sigma)=P(\\mu)P(\\sigma)$. Con esto, escribimos:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{array}{lcl}\n",
    "h_i & \\sim & \\text{Normal}(\\mu, \\sigma) \\\\\n",
    "\\mu & \\sim & \\text{Normal}(170, 20) \\\\\n",
    "\\sigma & \\sim & \\text{Uniform}(0, 50)\n",
    "\\end{array}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué significan estas previas?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La previa para $\\mu$ es una previa Gaussiana algo *amplia*, centrada en $170$ cm y con el $95$% de probabilidad concentrada en el intervalo $170 \\pm 40$ cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos scipy.stats norm y uniform\n",
    "\n",
    "# Pyplot\n",
    "\n",
    "# Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previa para mu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que el modelo asume que la **altura promedio** está, con alta probabilidad, entre $130$ cm y $210$ cm.\n",
    "\n",
    "Ahora, la previa para $\\sigma$ es plana; una distribución uniforme. Esta distribución restringe a $\\sigma$ a estar entre cero, y $50$ con igual probabilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previa para sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desviación estándar obviamente debe de ser positiva, por lo que hace sentido que la cota inferior de la uniforme sea cero. \n",
    "\n",
    "¿Qué significa que esté acotada en $50$ cm por arriba? Significa que las alturas individuales se encontrarán en un rango de $100$ cm alrededor de la altura promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo bastante importante, es que las previas hagan sentido, para lo cual una simulación **predictiva previa** es esencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librería Arviz: Análisis exploratorio de modelos Bayesianos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación previa predictiva\n",
    "N = 1000\n",
    "# Muestreo de la previa de mu\n",
    "\n",
    "# Muestreo de la previa de sigma\n",
    "\n",
    "# Muestreo de la verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_kde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que la distribución previa para la altura no es una Gaussiana. Esto es correcto. Es una distribución de las probabilidades de las diferentes alturas antes de ver los datos.\n",
    "\n",
    "La simulación predictiva previa es una herramienta poderosa para darnos cuenta que tan buenas son nuestras previas. A través de ella, nos podríamos dar cuenta que, por ejemplo, una previa $\\mu \\sim \\text{Normal}(170, 100)$, no sería adecuada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu ~ N(170, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación previa predictiva\n",
    "N = 1000\n",
    "# Muestreo de la previa de mu\n",
    "\n",
    "# Muestreo de la previa de sigma\n",
    "\n",
    "# Muestreo de la verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_kde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje de registros con altura negativa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta previa, estamos diciendo que el modelo antes de ver los datos, espera que $\\sim 5$% de la población tenga una altura *negativa*.\n",
    "\n",
    "¿Esto importa? Bueno, si tenemos una gran cantidad de datos, **NO**. Pero este no siempre será el caso. De cualquier forma, siempre convendrá tener previas que representen nuestro conocimiento lo mejor posible.\n",
    "\n",
    "Nos quedaremos con nuestras previas originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo usamos la simulación Montecarlo para estimar las distribuciones posteriores?**\n",
    "\n",
    "En el módulo pasado vimos que la simulación Montecarlo es una manera bastante efectiva de estimar distribuciones de probabilidad. \n",
    "\n",
    "La librería [pymc](https://www.pymc.io/welcome.html) automatiza la estimación de la distribución posterior haciendo uso de métodos MCMC, y con una sintaxis de python bastante sencilla, como veremos a continuación.\n",
    "\n",
    "Recordamos el modelo:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{array}{lcl}\n",
    "h_i & \\sim & \\text{Normal}(\\mu, \\sigma) \\\\\n",
    "\\mu & \\sim & \\text{Normal}(170, 20) \\\\\n",
    "\\sigma & \\sim & \\text{Uniform}(0, 50)\n",
    "\\end{array}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos pymc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo -- pm.Model()\n",
    "\n",
    "# mu ~ N(170, 20)\n",
    "\n",
    "# sigma ~ U(0, 50)\n",
    "\n",
    "# height ~ N(mu, sigma, observed=height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta acá solo hemos definido el modelo. Si queremos muestrear la distribución posterior usando MCMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pm.sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestreamos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos lo que contiene el objeto `idata` (inference data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto idata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el objeto `idata` está toda la información. Para visualizar gráficos de las distribuciones posteriores muestreadas, podemos hacer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O si lo queremos ver de forma numérica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de las distribuciones posteriores de los parámetros**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mebo2024_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
